{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Pre-Built & Custom AI Services\n",
    "\n",
    "In this notebook, you will integrate with the Computer Vision API and the Text Analytics API to augment the claims processing capabilities. In the end, you will integrate the API calls to the summarizer and classifier services that your deployed and produce a finished claim report that shows all of the processing applied to the claim text and claim image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup helper functions\n",
    "\n",
    "Run the cell below to enable helper functions to save locally the outputs as pickle files from the various cognitive services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "output_location = './cs_outputs'\n",
    "os.makedirs(output_location, exist_ok=True)\n",
    "\n",
    "def save_output(output, name):\n",
    "    file_name = os.path.join(output_location, name) + '.pkl'\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(output, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def get_output(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Caption & Tag with the Computer Vision API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow, provided the key to your Computer Vision API and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = '' #\"<your_computer_vision_api_key>\"\n",
    "assert subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the endpoint to the Computer Vision API by running the following cell. Notice the last path segment is analyze, which indicates you will use the analyze feature.\n",
    "\n",
    "Be sure to update the value in vision_endpoint below so it matches the Endpoint value you copied from the Azure Portal for your instance of the Computer Vision service. Be sure your value ends in a slash (/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_endpoint = '' #\"<your_computer_vision_api_endpoint>\"\n",
    "vision_base_url = vision_endpoint + \"vision/v3.0/\"\n",
    "vision_analyze_url = vision_base_url + \"analyze\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a list of sample images found after performing a simple web search. Feel free to substitute in URLs to the image of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fender_bender = \"https://www.washingtonpost.com/blogs/innovations/files/2015/02/Stolen_Car_Crash-00aef.jpg\"\n",
    "damaged_house = \"https://c2.staticflickr.com/8/7342/10983313185_0589b74946_z.jpg\"\n",
    "police_car = \"https://localtvwnep.files.wordpress.com/2015/11/fender-bender.jpeg\"\n",
    "car_with_text = \"https://static.buildasign.com/cmsimages/bas-vinyl-lettering-splash-01.png\"\n",
    "car_tow = 'https://i.ytimg.com/vi/wmxJ2FrzTWo/maxresdefault.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of images above, select one and assign it to image_url for further processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = car_tow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to preview the image you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell builds the HTTP request to make against the Computer Vision API.\n",
    "\n",
    "Run the following cell to retrieve the caption and tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "params   = {'visualFeatures': 'Categories,Description,Tags,Color'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(vision_analyze_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "analysis = response.json()\n",
    "# Save the ouput locally\n",
    "save_output(analysis, 'vision_results')\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above output, the result is a nested document structure. Run the following cells to pull out the caption and top 3 tag results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topTags = analysis[\"description\"][\"tags\"][0:3]\n",
    "topTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Performing OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform OCR with the Computer Vision service, you need to target the OCR endpoint.\n",
    "\n",
    "Run the following cell to construct the right URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_ocr_url = vision_base_url + \"ocr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, invoke the OCR endpoint with the following code and examine the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "params   = {}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(vision_ocr_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "ocr_analysis = response.json()\n",
    "# Save the ouput locally\n",
    "save_output(ocr_analysis, 'ocr_results')\n",
    "ocr_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided the following code for you to extract the text as a flat array from the results.\n",
    "\n",
    "Run the following cell to extract the text items from the results document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "flatten = lambda x: list(itertools.chain.from_iterable(x))\n",
    "words_list = [[ [w['text'] for w in line['words']]  for line in d['lines']] for d in ocr_analysis['regions']]\n",
    "words_list = flatten(flatten(words_list))\n",
    "print(list(words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Performing Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis is performed using the Text Analytics API.\n",
    "\n",
    "Update the following cell with the key to your instance of the Text Analytics API and run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analytics_subscription_key = '' #\"<your_text_analytics_key>\"\n",
    "assert text_analytics_subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the following cell with the correct Endpoint URL for your deployed instance of the Text Analytics API and run the cell. Be sure your value ends in a slash (/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"<your_text_analytics_api_endpoint>\"\n",
    "text_analytics_base_url = ''\n",
    "sentiment_api_url = text_analytics_base_url + \"text/analytics/v3.0/sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell has a set of example claims you can use to test the measurement sentiment.\n",
    "\n",
    "Run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sent = \"\"\"We are just devastated and emotionally drained. \n",
    "The roof was torn off of our car, and to make matters\n",
    "worse my daughter's favorite teddy bear was impaled on the street lamp.\"\"\"\n",
    "pos_sent = \"\"\"We are just happy the damaage was mininmal and that everyone is safe. \n",
    "We are thankful for your support.\"\"\"\n",
    "neutral_sent = \"\"\"I crashed my car.\"\"\"\n",
    "long_claim = \"\"\"\n",
    "I was driving down El Camino and stopped at a red light.\n",
    "It was about 3pm in the afternoon. The sun was bright and shining just behind the stoplight.\n",
    "This made it hard to see the lights. There was a car on my left in the left turn lane.\n",
    "A few moments later another car, a black sedan pulled up behind me. \n",
    "When the left turn light changed green, the black sedan hit me thinking \n",
    "that the light had changed for us, but I had not moved because the light \n",
    "was still red. After hitting my car, the black sedan backed up and then sped past me.\n",
    "I did manage to catch its license plate. The license plate of the black sedan was ABC123. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above list of claims, select one and assign its variable to claim_text to be used in the call to the Text Analytics API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_text = long_claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API requires you to submit a document of the following form.\n",
    "\n",
    "Run the cell to build the request document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {'documents' : [\n",
    "    {'id': '1', 'language': 'en', 'text': claim_text}\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now invoke the Text Analytics API and observe the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers   = {\"Ocp-Apim-Subscription-Key\": text_analytics_subscription_key}\n",
    "response  = requests.post(sentiment_api_url, headers=headers, json=documents)\n",
    "sentiments = response.json()\n",
    "# Save the ouput locally\n",
    "save_output(sentiments, 'sentiment_results')\n",
    "sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the Text Analytics API provides breakdown of sentiments at the individual sentence levels. Run the following cell to view the overall sentiment of the document and sentiment breakdown by sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_interpretation = sentiments['documents'][0]['sentiment']\n",
    "print('Overall document sentiment:', score_interpretation)\n",
    "print('')\n",
    "print('Sentiment breakdown by sentences')\n",
    "for item in sentiments['documents'][0]['sentences']:\n",
    "    print('Sentence:', item['text'].strip(), 'Sentiment:', item['sentiment'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Save the Results in Blob Store\n",
    "\n",
    "Save the JSON responses that came from the various cognitive services to a permanent store like the blob storage for future reference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been saving the JSON outputs as pickle files temporarily in a local directory. Let’s review the saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $output_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the `Workspace` from the saved config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload the files from the local directory to the default blob store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(output_location, \n",
    "                 target_path = 'cs_results', \n",
    "                 overwrite = True, \n",
    "                 show_progress = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to your resource group’s storage account, select **Containers**, and then select the default blob store **azureml-blobstore-xxx**. Next, select the folder **cs_results** to view the saved files.\n",
    "\n",
    "\n",
    "![Image showing uploaded results from the cognitive services APIs.](./images/blob_files.png 'Blobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Invoking the Azure ML Deployed Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to define a method that will be used to invoke your classifier and summarizer methods deployed using Azure Machine Learning service to Azure Container Instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_service(ml_service_key, ml_service_scoring_endpoint, ml_service_input):\n",
    "    headers   = {\"Authorization\": \"Bearer \" + ml_service_key}\n",
    "    response  = requests.post(ml_service_scoring_endpoint, headers=headers, json=ml_service_input)\n",
    "    result = response.json()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the classifier invocation with the key and endpoint as appropriate to your deployed instance:\n",
    "\n",
    "> This is the scoring URI you copied from the notebook named `04 Deploy Classifier Web Service.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_service_key = \"\" #leave this value empty if the service does not have authentication enabled\n",
    "#\"<your_classifier_scoring_url>\"\n",
    "classifier_service_scoring_endpoint = ''\n",
    "classifier_service_input = [claim_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the classifier and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_result = invoke_service(classifier_service_key, \n",
    "                                   classifier_service_scoring_endpoint, classifier_service_input)\n",
    "classifier_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the classifier result\n",
    "classification = 'Auto Insurance Claim' if classifier_result == 1 else 'Home Insurance Claim' \n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, configure the key and scoring endpoint as appropriate to your summarizer service:\n",
    "\n",
    "> This is the scoring URI you copied from the notebook named `02 Deploy Summarizer Web Service.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_service_key = \"\" #leave this value empty if the service does not have authentication enabled\n",
    "#\"<your_summarizer_service_url>\"\n",
    "summarizer_service_scoring_endpoint = ''\n",
    "summarizer_service_input = claim_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the summarizer service and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_result = invoke_service(summarizer_service_key, summarizer_service_scoring_endpoint, \n",
    "                                   summarizer_service_input)\n",
    "formatted_result =  summarizer_result[0].replace(\"\\\\n\", \" \").strip() if len(summarizer_result) > 0 else \"N/A\"\n",
    "formatted_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 - Summarizing the Results\n",
    "\n",
    "In this final task, you pull together all of the pieces to display the results of your AI based processing.\n",
    "\n",
    "Run the following cell and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "displayTemplate = \"\"\"\n",
    "<div><b>Claim Summary</b></div>\n",
    "<div>Classification: {}</div>\n",
    "<div>Caption: {}</div>\n",
    "<div>Tags: {}</div>\n",
    "<div>Text in Image: {}</div>\n",
    "<div>Sentiment: {}</div>\n",
    "<div><img src='{}' width='200px'></div>\n",
    "<div>Summary: </div>\n",
    "<div><pre>{} </pre></div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Claim:</div>\n",
    "<div>{}</div>\n",
    "\n",
    "\"\"\"\n",
    "displayTemplate = displayTemplate.format(classification, caption, ' '.join(topTags), ' '.join(words_list), \n",
    "                                         score_interpretation, image_url, formatted_result, \n",
    "                                         claim_text)\n",
    "display(HTML(displayTemplate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}